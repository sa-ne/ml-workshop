# AI/ML Workshop

Welcome to the AI/ML workshop quickstart guide!

This guide is intended to help you understand some fundamentals of AI/ML tools provided under the Open Data Hub project.

Before we get started let's cover some topics related to the infrastructure for this workshop. The environment where we will be working on labs is running on RHPDS and you should have gotten an email with more details about your OpenShift cluster.

Although we cover the installation of Open Data Hub, we will be deploying it only (creation of the ODH CRs onto your project namespace) as the operator was already installed as part of the cluster provisioning process.

In relation to the content, we will cover the four most common use cases of ODH as follows:

- How to provision ODH and what components are deployed/configured, giving some cotext of what actually each component is.
- How to run a simple Jupyter Notebook using the JupyterHub instance created by ODH.
- How to access data from your Jupyter notebook to start performing your experiments.
- How to run your first Kubeflow pipeline and how to use Elyra to build your pipelines.
- How to run prediction on user provided data through pre-trained models provided with AI Library.

So let's get our machines to learn!
